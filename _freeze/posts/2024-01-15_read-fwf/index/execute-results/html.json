{
  "hash": "8f7b284971c0bf6eae3456b0d6ca4b2f",
  "result": {
    "markdown": "---\ntitle: Read dirty tab-separated CSV files\nauthor:\n  - name:\n      given: Layal Christine\n      family: Lettry\n      orcid: 0009-0008-6396-0523\n    affiliations:\n      - id: cynkra\n      - name: cynkra GmbH\n        city: Zurich\n        state: CH\n      - id: unifr\n      - name: University of Fribourg, Dept. of Informatics, ASAM Group\n        city: Fribourg\n        state: CH\ndate: 2024-01-15\ncategories: [readr, read_fwf, tab, CSV]\nimage: image.jpg\ncitation: \n  url: https://rdiscovery.netlify.app/posts/2024-01-15_read-fwf/\nformat:\n  html:\n    toc: true\n    toc-depth: 6\n    toc-title: Contents\n    toc-location: right\n    number-sections: false\neditor_options: \n  chunk_output_type: console\n---\n\n\n*What function could be used to read tab-separated CSV files with values containing a tab?*\n\n# Template CSV\n\nLet's create a new tab-separated CSV. The second observation contains a tab instead of a space in the `name` variable. This will lead to a problem when reading the CSV file.\n\n\n::: {.cell tbl-cap='Create a tab-separated CSV'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndata <- tibble(\n  id = c(1, 2, 3),\n  name = c(\"John Doe\", \"Jane\\tSmith\", \"Bob Johnson\"),\n  age =  c(25, 30, 35)\n)\n\nfile <- tempfile(fileext = \".csv\")\n\nwrite.table(data, file, sep = \"\\t\", quote = FALSE, row.names = FALSE)\n\nfile_encoding <-\n  guess_encoding(file) |>\n  pull(encoding)\n```\n:::\n\n\n# Reading problem \n\nWhen you read your data, you will receive a warning message telling you to run `vroom::problems()` on your output. This shows how many columns were expected and actually read. You can see that only three columns were expected but four columns were actually detected. \n\nMoreover, the family name of the second observation was merged to the `age` value, which leads to a `NA` when converting it to an integer.\n\nThis is due to the tab contained in the value of the `name` variable for the second observation. \n\nYou could also get the following error message (sorry, I could not reproduce this error that led me to write this post):\n\n`` `Stopped early on line 2. Expected 3 fields but found 4 Consider fill=TRUE and comment.char=.` ``\n\n\n\n::: {.cell tbl-cap='Read with `read_delim()`'}\n\n```{.r .cell-code}\nread_data <- read_delim(file,\n  delim = \"\\t\",\n  locale = readr::locale(encoding = file_encoding),\n  col_types = cols(age = col_integer(), .default = col_character())\n)\n\nread_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  id    name          age\n  <chr> <chr>       <int>\n1 1     John Doe       25\n2 2     Jane           NA\n3 3     Bob Johnson    35\n```\n:::\n\n```{.r .cell-code}\nvroom::problems(read_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n    row   col expected   actual      file                                       \n  <int> <int> <chr>      <chr>       <chr>                                      \n1     3     3 an integer \"Smith\\t30\" /private/var/folders/nt/m0krkrqx6jgcl_9km5…\n2     3     4 3 columns  \"4 columns\" /private/var/folders/nt/m0krkrqx6jgcl_9km5…\n```\n:::\n:::\n\n\n# Reading solution\nOne solution I found to override the error quoted above was to read the entire CSV file except for the first row with variable names, thanks to the function `read_fwf()`. All the information is then saved in a single column called `X1`. \n\n\n::: {.cell tbl-cap='Save the data in one column with `read_fwf()`'}\n\n```{.r .cell-code}\nraw_data <-\n  read_fwf(\n    file,\n    col_types = cols(.default = col_character()),\n    locale = locale(encoding = file_encoding),\n    skip = 1L\n  )\n\nraw_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 1\n  X1                  \n  <chr>               \n1 \"1\\tJohn Doe\\t25\"   \n2 \"2\\tJane\\tSmith\\t30\"\n3 \"3\\tBob Johnson\\t35\"\n```\n:::\n:::\n\n\nThe next thing to do is to read the headers separately and to separate the columns thanks to `separate_wider_delim()`. The problematic value containing a tab will be merged with the following column value, leading to an `NA` when setting the integer type to this column. \n\n\n::: {.cell tbl-cap='Clean the data'}\n\n```{.r .cell-code}\nheaders <- strsplit(readLines(file, n = 1L), \"\\t\")[[1]]\ncol_names <- gsub(\"\\\"\", \"\", headers)\n\nout <- raw_data |>\n  separate_wider_delim(\n    cols = X1,\n    names = col_names,\n    delim = \"\\t\",\n    too_many = \"merge\" \n  ) |>\n  mutate(\n    across(everything(), \\(x) gsub('\"', \"\", x))\n  )\n\nraw_dirty <- out |>\n  mutate(\n    id = as.integer(id),\n    age = as.integer(age)\n  )\n\nraw_clean <- janitor::clean_names(raw_dirty)\n\nraw_clean\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n     id name          age\n  <int> <chr>       <int>\n1     1 John Doe       25\n2     2 Jane           NA\n3     3 Bob Johnson    35\n```\n:::\n:::\n\n\n\n# Conclusion\n\nI agree with you that the solution I found with `read_fwf()` and `separate_wider_delim()` is more complicated than the one with `read_delim()`. \n\nHowever, this solved my problem of partially reading the CSV file, although I could not reproduce it in this example, namely:\n\n`` `Stopped early on line 2. Expected 3 fields but found 4 Consider fill=TRUE and comment.char=.` ``\n\nThanks to `read_fwf()`, I can read all the rows. Then, I separate the columns with `separate_wider_delim()` and merge the wrong additional columns values containing an extra tab together thanks to the option `too_many = \"merge\"`. \n\nEventually, by converting my `age` variable to an integer type, the merged values are transformed into an `NA`. This does not bother me, since this row will certainly get dropped in my following calculations, as the original typed data were wrong for this observation.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}